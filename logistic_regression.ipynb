{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/Users/satviksingh/Documents/manas_projects/logistic regression/crime_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04725751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data \n",
    "\n",
    "# Remove useless columns\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"Num\"])\n",
    "\n",
    "# Convert Yes/No â†’ 1/0\n",
    "df[\"closed\"] = df[\"closed\"].map({\"Yes\": 1, \"No\": 0}).astype(int)\n",
    "\n",
    "# Convert datetime\n",
    "df[\"case_filed\"] = pd.to_datetime(df[\"case_filed\"], errors=\"coerce\")\n",
    "df[\"year\"] = df[\"case_filed\"].dt.year\n",
    "df[\"month\"] = df[\"case_filed\"].dt.month\n",
    "df[\"hour\"]  = df[\"case_filed\"].dt.hour\n",
    "df = df.drop(columns=[\"case_filed\"])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(df, columns=[\"city\", \"crime_description\", \"sex\", \"weapon\", \"domain\"])\n",
    "\n",
    "# Convert to numpy\n",
    "X = df.drop(columns=[\"closed\"]).values.astype(float)\n",
    "y = df[\"closed\"].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856cc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some more pre preprocessing \n",
    "\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0) + 1e-8\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "# Add bias term\n",
    "m = X.shape[0]\n",
    "X = np.hstack([np.ones((m, 1)), X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646220e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SIGMOID + log loss\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def predict_proba(X, weights):\n",
    "    return sigmoid(np.dot(X, weights))\n",
    "\n",
    "def compute_loss(y, y_pred):\n",
    "    m = len(y)\n",
    "    eps = 1e-9\n",
    "    return -(1/m) * np.sum(\n",
    "        y*np.log(y_pred + eps) + (1-y)*np.log(1-y_pred + eps)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02fb6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. TRAINING FUNCTION\n",
    "\n",
    "def train_logistic_regression(X, y, lr=0.0002, epochs=100000):\n",
    "    m, n = X.shape\n",
    "    weights = np.zeros((n, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = predict_proba(X, weights)\n",
    "        gradient = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "        weights -= lr * gradient\n",
    "\n",
    "        # Print status every 1000 epochs\n",
    "        if epoch % 1000 == 0:\n",
    "            loss = compute_loss(y, y_pred)\n",
    "            print(f\"Epoch {epoch:6d} | Loss: {loss:.6f}\")\n",
    "\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ece57e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch      0 | Loss: 0.693147\n",
      "Epoch   1000 | Loss: 0.693046\n",
      "Epoch   2000 | Loss: 0.692958\n",
      "Epoch   3000 | Loss: 0.692880\n",
      "Epoch   4000 | Loss: 0.692811\n",
      "Epoch   5000 | Loss: 0.692750\n",
      "Epoch   6000 | Loss: 0.692696\n",
      "Epoch   7000 | Loss: 0.692649\n",
      "Epoch   8000 | Loss: 0.692606\n",
      "Epoch   9000 | Loss: 0.692568\n",
      "Epoch  10000 | Loss: 0.692535\n",
      "Epoch  11000 | Loss: 0.692505\n",
      "Epoch  12000 | Loss: 0.692478\n",
      "Epoch  13000 | Loss: 0.692454\n",
      "Epoch  14000 | Loss: 0.692433\n",
      "Epoch  15000 | Loss: 0.692414\n",
      "Epoch  16000 | Loss: 0.692396\n",
      "Epoch  17000 | Loss: 0.692381\n",
      "Epoch  18000 | Loss: 0.692367\n",
      "Epoch  19000 | Loss: 0.692355\n",
      "Epoch  20000 | Loss: 0.692344\n",
      "Epoch  21000 | Loss: 0.692334\n",
      "Epoch  22000 | Loss: 0.692325\n",
      "Epoch  23000 | Loss: 0.692317\n",
      "Epoch  24000 | Loss: 0.692310\n",
      "Epoch  25000 | Loss: 0.692303\n",
      "Epoch  26000 | Loss: 0.692297\n",
      "Epoch  27000 | Loss: 0.692292\n",
      "Epoch  28000 | Loss: 0.692287\n",
      "Epoch  29000 | Loss: 0.692283\n",
      "Epoch  30000 | Loss: 0.692279\n",
      "Epoch  31000 | Loss: 0.692276\n",
      "Epoch  32000 | Loss: 0.692273\n",
      "Epoch  33000 | Loss: 0.692270\n",
      "Epoch  34000 | Loss: 0.692267\n",
      "Epoch  35000 | Loss: 0.692265\n",
      "Epoch  36000 | Loss: 0.692263\n",
      "Epoch  37000 | Loss: 0.692261\n",
      "Epoch  38000 | Loss: 0.692259\n",
      "Epoch  39000 | Loss: 0.692258\n",
      "Epoch  40000 | Loss: 0.692256\n",
      "Epoch  41000 | Loss: 0.692255\n",
      "Epoch  42000 | Loss: 0.692254\n",
      "Epoch  43000 | Loss: 0.692253\n",
      "Epoch  44000 | Loss: 0.692252\n",
      "Epoch  45000 | Loss: 0.692251\n",
      "Epoch  46000 | Loss: 0.692250\n",
      "Epoch  47000 | Loss: 0.692249\n",
      "Epoch  48000 | Loss: 0.692249\n",
      "Epoch  49000 | Loss: 0.692248\n",
      "Epoch  50000 | Loss: 0.692248\n",
      "Epoch  51000 | Loss: 0.692247\n",
      "Epoch  52000 | Loss: 0.692247\n",
      "Epoch  53000 | Loss: 0.692246\n",
      "Epoch  54000 | Loss: 0.692246\n",
      "Epoch  55000 | Loss: 0.692245\n",
      "Epoch  56000 | Loss: 0.692245\n",
      "Epoch  57000 | Loss: 0.692245\n",
      "Epoch  58000 | Loss: 0.692244\n",
      "Epoch  59000 | Loss: 0.692244\n",
      "Epoch  60000 | Loss: 0.692244\n",
      "Epoch  61000 | Loss: 0.692244\n",
      "Epoch  62000 | Loss: 0.692243\n",
      "Epoch  63000 | Loss: 0.692243\n",
      "Epoch  64000 | Loss: 0.692243\n",
      "Epoch  65000 | Loss: 0.692243\n",
      "Epoch  66000 | Loss: 0.692243\n",
      "Epoch  67000 | Loss: 0.692243\n",
      "Epoch  68000 | Loss: 0.692242\n",
      "Epoch  69000 | Loss: 0.692242\n",
      "Epoch  70000 | Loss: 0.692242\n",
      "Epoch  71000 | Loss: 0.692242\n",
      "Epoch  72000 | Loss: 0.692242\n",
      "Epoch  73000 | Loss: 0.692242\n",
      "Epoch  74000 | Loss: 0.692242\n",
      "Epoch  75000 | Loss: 0.692242\n",
      "Epoch  76000 | Loss: 0.692241\n",
      "Epoch  77000 | Loss: 0.692241\n",
      "Epoch  78000 | Loss: 0.692241\n",
      "Epoch  79000 | Loss: 0.692241\n",
      "Epoch  80000 | Loss: 0.692241\n",
      "Epoch  81000 | Loss: 0.692241\n",
      "Epoch  82000 | Loss: 0.692241\n",
      "Epoch  83000 | Loss: 0.692241\n",
      "Epoch  84000 | Loss: 0.692241\n",
      "Epoch  85000 | Loss: 0.692241\n",
      "Epoch  86000 | Loss: 0.692241\n",
      "Epoch  87000 | Loss: 0.692241\n",
      "Epoch  88000 | Loss: 0.692240\n",
      "Epoch  89000 | Loss: 0.692240\n",
      "Epoch  90000 | Loss: 0.692240\n",
      "Epoch  91000 | Loss: 0.692240\n",
      "Epoch  92000 | Loss: 0.692240\n",
      "Epoch  93000 | Loss: 0.692240\n",
      "Epoch  94000 | Loss: 0.692240\n",
      "Epoch  95000 | Loss: 0.692240\n",
      "Epoch  96000 | Loss: 0.692240\n",
      "Epoch  97000 | Loss: 0.692240\n",
      "Epoch  98000 | Loss: 0.692240\n",
      "Epoch  99000 | Loss: 0.692240\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# 5. TRAIN MODEL\n",
    "\n",
    "print(\"Starting training...\")\n",
    "weights = train_logistic_regression(X, y)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0d52151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= RESULT =======================\n",
      "Final Loss:      0.692240\n",
      "Final Accuracy:  0.514474\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "def predict(X, weights, threshold=0.5):\n",
    "    return (predict_proba(X, weights) >= threshold).astype(int)\n",
    "\n",
    "y_pred = predict(X, weights)\n",
    "accuracy = np.mean(y_pred == y)\n",
    "\n",
    "final_loss = compute_loss(y, predict_proba(X, weights))\n",
    "\n",
    "print(\"\\n======================= RESULT =======================\")\n",
    "print(f\"Final Loss:      {final_loss:.6f}\")\n",
    "print(f\"Final Accuracy:  {accuracy:.6f}\")\n",
    "print(\"======================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a60dd0",
   "metadata": {},
   "source": [
    "this test was done with old data \n",
    "doing another test with test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0bfb342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TEST SET RESULT ===================\n",
      "Test Set Accuracy:   0.492582\n",
      "Training Accuracy:   0.514474\n",
      "Accuracy Difference: 0.021892\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load new dataset\n",
    "df_new = pd.read_csv(\"/Users/satviksingh/Documents/manas_projects/logistic regression/crime_test.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "df_new = df_new.drop(columns=[\"Unnamed: 0\", \"Num\"])\n",
    "df_new[\"closed\"] = df_new[\"closed\"].map({\"Yes\": 1, \"No\": 0}).astype(int)\n",
    "\n",
    "# Convert datetime\n",
    "df_new[\"case_filed\"] = pd.to_datetime(df_new[\"case_filed\"], errors=\"coerce\")\n",
    "df_new[\"year\"] = df_new[\"case_filed\"].dt.year\n",
    "df_new[\"month\"] = df_new[\"case_filed\"].dt.month\n",
    "df_new[\"hour\"]  = df_new[\"case_filed\"].dt.hour\n",
    "df_new = df_new.drop(columns=[\"case_filed\"])\n",
    "\n",
    "# One-hot encode \n",
    "df_new = pd.get_dummies(df_new, columns=[\"city\", \"crime_description\", \"sex\", \"weapon\", \"domain\"])\n",
    "\n",
    "# Align columns: Test data must have the same features in the same order as training data\n",
    "# Any categories missing in the test set but present in training must be added as 0s\n",
    "for col in df.columns:\n",
    "    if col not in df_new.columns:\n",
    "        df_new[col] = 0\n",
    "\n",
    "# Select only the columns that were in the original training set (excluding target)\n",
    "train_features = [col for col in df.columns if col != \"closed\"]\n",
    "X_new = df_new[train_features].values.astype(float)\n",
    "y_new = df_new[\"closed\"].values.reshape(-1, 1)\n",
    "\n",
    "# 3. Feature Scaling using TRAINING statistics (X_mean, X_std)\n",
    "X_new = (X_new - X_mean) / X_std\n",
    "\n",
    "# Add bias term\n",
    "m_new = X_new.shape[0]\n",
    "X_new = np.hstack([np.ones((m_new, 1)), X_new])\n",
    "\n",
    "# 4. Final Predictions and Comparison\n",
    "y_pred_new = predict(X_new, weights)\n",
    "accuracy_new = np.mean(y_pred_new == y_new)\n",
    "\n",
    "print(\"\\n==================== TEST SET RESULT ===================\")\n",
    "print(f\"Test Set Accuracy:   {accuracy_new:.6f}\")\n",
    "print(f\"Training Accuracy:   {accuracy:.6f}\")\n",
    "print(f\"Accuracy Difference: {abs(accuracy - accuracy_new):.6f}\")\n",
    "print(\"==========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d61fa3",
   "metadata": {},
   "source": [
    "poor acuracy \n",
    "    almost equivalent ot a coin toss \n",
    "\n",
    "    maybe because the data was \n",
    "        highly catagorical \n",
    "        non linear \n",
    "\n",
    "or maybe i made a mistake \n",
    "\n",
    "proposed solution \n",
    "    use discision trees \n",
    "    might work better on such catgorical data \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
